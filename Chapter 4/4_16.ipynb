{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 16\n",
    "\n",
    "cf. [Boston data set documentation](https://islp.readthedocs.io/en/latest/datasets/Boston.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13),\n",
       " Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "        'ptratio', 'lstat', 'medv'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP import confusion_table\n",
    "from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from ISLP.models import ModelSpec as MS\n",
    "\n",
    "Boston = load_data(\"Boston\")\n",
    "Boston.shape, Boston.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       lstat  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
       "\n",
       "             medv  \n",
       "count  506.000000  \n",
       "mean    22.532806  \n",
       "std      9.197104  \n",
       "min      5.000000  \n",
       "25%     17.025000  \n",
       "50%     21.200000  \n",
       "75%     25.000000  \n",
       "max     50.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria = Boston.crim > Boston.crim.median()\n",
    "crim01 = np.array([\"0\"]*Boston.shape[0])\n",
    "crim01[criteria] = \"1\"\n",
    "Boston[\"crim01\"] = crim01\n",
    "\n",
    "Boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   253</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   240</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -50.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 12 Sep 2023</td> <th>  Deviance:          </th> <td>  100.74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:04:17</td>     <th>  Pearson chi2:      </th>  <td>  666.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>9</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.6270</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zn</th>        <td>   -0.0713</td> <td>    0.044</td> <td>   -1.637</td> <td> 0.102</td> <td>   -0.157</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>indus</th>     <td>   -0.1543</td> <td>    0.075</td> <td>   -2.070</td> <td> 0.038</td> <td>   -0.300</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chas</th>      <td>    0.9984</td> <td>    1.010</td> <td>    0.988</td> <td> 0.323</td> <td>   -0.982</td> <td>    2.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nox</th>       <td>   53.2761</td> <td>   11.503</td> <td>    4.631</td> <td> 0.000</td> <td>   30.730</td> <td>   75.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rm</th>        <td>   -0.3268</td> <td>    1.014</td> <td>   -0.322</td> <td> 0.747</td> <td>   -2.315</td> <td>    1.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.0303</td> <td>    0.017</td> <td>    1.816</td> <td> 0.069</td> <td>   -0.002</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>    0.8007</td> <td>    0.340</td> <td>    2.357</td> <td> 0.018</td> <td>    0.135</td> <td>    1.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rad</th>       <td>    0.6037</td> <td>    0.226</td> <td>    2.671</td> <td> 0.008</td> <td>    0.161</td> <td>    1.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tax</th>       <td>   -0.0033</td> <td>    0.004</td> <td>   -0.811</td> <td> 0.417</td> <td>   -0.011</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ptratio</th>   <td>    0.5476</td> <td>    0.200</td> <td>    2.737</td> <td> 0.006</td> <td>    0.156</td> <td>    0.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lstat</th>     <td>    0.2114</td> <td>    0.076</td> <td>    2.773</td> <td> 0.006</td> <td>    0.062</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>medv</th>      <td>    0.2765</td> <td>    0.116</td> <td>    2.377</td> <td> 0.017</td> <td>    0.049</td> <td>    0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>  -51.3460</td> <td>   10.827</td> <td>   -4.742</td> <td> 0.000</td> <td>  -72.566</td> <td>  -30.126</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        y         & \\textbf{  No. Observations:  } &      253    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &      240    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &       12    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -50.369   \\\\\n",
       "\\textbf{Date:}            & Tue, 12 Sep 2023 & \\textbf{  Deviance:          } &    100.74   \\\\\n",
       "\\textbf{Time:}            &     10:04:17     & \\textbf{  Pearson chi2:      } &     666.    \\\\\n",
       "\\textbf{No. Iterations:}  &        9         & \\textbf{  Pseudo R-squ. (CS):} &   0.6270    \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{zn}        &      -0.0713  &        0.044     &    -1.637  &         0.102        &       -0.157    &        0.014     \\\\\n",
       "\\textbf{indus}     &      -0.1543  &        0.075     &    -2.070  &         0.038        &       -0.300    &       -0.008     \\\\\n",
       "\\textbf{chas}      &       0.9984  &        1.010     &     0.988  &         0.323        &       -0.982    &        2.979     \\\\\n",
       "\\textbf{nox}       &      53.2761  &       11.503     &     4.631  &         0.000        &       30.730    &       75.822     \\\\\n",
       "\\textbf{rm}        &      -0.3268  &        1.014     &    -0.322  &         0.747        &       -2.315    &        1.661     \\\\\n",
       "\\textbf{age}       &       0.0303  &        0.017     &     1.816  &         0.069        &       -0.002    &        0.063     \\\\\n",
       "\\textbf{dis}       &       0.8007  &        0.340     &     2.357  &         0.018        &        0.135    &        1.466     \\\\\n",
       "\\textbf{rad}       &       0.6037  &        0.226     &     2.671  &         0.008        &        0.161    &        1.047     \\\\\n",
       "\\textbf{tax}       &      -0.0033  &        0.004     &    -0.811  &         0.417        &       -0.011    &        0.005     \\\\\n",
       "\\textbf{ptratio}   &       0.5476  &        0.200     &     2.737  &         0.006        &        0.156    &        0.940     \\\\\n",
       "\\textbf{lstat}     &       0.2114  &        0.076     &     2.773  &         0.006        &        0.062    &        0.361     \\\\\n",
       "\\textbf{medv}      &       0.2765  &        0.116     &     2.377  &         0.017        &        0.049    &        0.505     \\\\\n",
       "\\textbf{intercept} &     -51.3460  &       10.827     &    -4.742  &         0.000        &      -72.566    &      -30.126     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  253\n",
       "Model:                            GLM   Df Residuals:                      240\n",
       "Model Family:                Binomial   Df Model:                           12\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -50.369\n",
       "Date:                Tue, 12 Sep 2023   Deviance:                       100.74\n",
       "Time:                        10:04:17   Pearson chi2:                     666.\n",
       "No. Iterations:                     9   Pseudo R-squ. (CS):             0.6270\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "zn            -0.0713      0.044     -1.637      0.102      -0.157       0.014\n",
       "indus         -0.1543      0.075     -2.070      0.038      -0.300      -0.008\n",
       "chas           0.9984      1.010      0.988      0.323      -0.982       2.979\n",
       "nox           53.2761     11.503      4.631      0.000      30.730      75.822\n",
       "rm            -0.3268      1.014     -0.322      0.747      -2.315       1.661\n",
       "age            0.0303      0.017      1.816      0.069      -0.002       0.063\n",
       "dis            0.8007      0.340      2.357      0.018       0.135       1.466\n",
       "rad            0.6037      0.226      2.671      0.008       0.161       1.047\n",
       "tax           -0.0033      0.004     -0.811      0.417      -0.011       0.005\n",
       "ptratio        0.5476      0.200      2.737      0.006       0.156       0.940\n",
       "lstat          0.2114      0.076      2.773      0.006       0.062       0.361\n",
       "medv           0.2765      0.116      2.377      0.017       0.049       0.505\n",
       "intercept    -51.3460     10.827     -4.742      0.000     -72.566     -30.126\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(Boston.drop(columns=[\"crim\",\"crim01\"]), crim01, test_size=0.5, random_state=0)\n",
    "\n",
    "# For logistic regression, we need to add the intercept (if you use MS it will add it for you, but I want to use the same sets for all methods)\n",
    "X_train_ = X_train\n",
    "X_test_ = X_test\n",
    "X_train_[\"intercept\"] = 1\n",
    "X_test_[\"intercept\"] = 1\n",
    "\n",
    "glm = sm.GLM(y_train == \"1\",X_train_,family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary we can see that `zn`, `chas`, `rm` and `tax` are not statistically significant to predict the response.\n",
    "So we will try again by removing these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   253</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   244</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -54.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 12 Sep 2023</td> <th>  Deviance:          </th> <td>  108.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:04:17</td>     <th>  Pearson chi2:      </th>  <td>  256.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>9</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.6156</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>indus</th>     <td>   -0.1912</td> <td>    0.068</td> <td>   -2.822</td> <td> 0.005</td> <td>   -0.324</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nox</th>       <td>   51.1504</td> <td>   11.473</td> <td>    4.458</td> <td> 0.000</td> <td>   28.664</td> <td>   73.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.0274</td> <td>    0.014</td> <td>    1.963</td> <td> 0.050</td> <td> 4.48e-05</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>    0.5948</td> <td>    0.254</td> <td>    2.342</td> <td> 0.019</td> <td>    0.097</td> <td>    1.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rad</th>       <td>    0.4892</td> <td>    0.162</td> <td>    3.027</td> <td> 0.002</td> <td>    0.172</td> <td>    0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ptratio</th>   <td>    0.5354</td> <td>    0.172</td> <td>    3.120</td> <td> 0.002</td> <td>    0.199</td> <td>    0.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lstat</th>     <td>    0.2320</td> <td>    0.072</td> <td>    3.205</td> <td> 0.001</td> <td>    0.090</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>medv</th>      <td>    0.2486</td> <td>    0.070</td> <td>    3.535</td> <td> 0.000</td> <td>    0.111</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>  -50.9489</td> <td>   10.325</td> <td>   -4.935</td> <td> 0.000</td> <td>  -71.185</td> <td>  -30.713</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        y         & \\textbf{  No. Observations:  } &      253    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &      244    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        8    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -54.190   \\\\\n",
       "\\textbf{Date:}            & Tue, 12 Sep 2023 & \\textbf{  Deviance:          } &    108.38   \\\\\n",
       "\\textbf{Time:}            &     10:04:17     & \\textbf{  Pearson chi2:      } &     256.    \\\\\n",
       "\\textbf{No. Iterations:}  &        9         & \\textbf{  Pseudo R-squ. (CS):} &   0.6156    \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{indus}     &      -0.1912  &        0.068     &    -2.822  &         0.005        &       -0.324    &       -0.058     \\\\\n",
       "\\textbf{nox}       &      51.1504  &       11.473     &     4.458  &         0.000        &       28.664    &       73.637     \\\\\n",
       "\\textbf{age}       &       0.0274  &        0.014     &     1.963  &         0.050        &     4.48e-05    &        0.055     \\\\\n",
       "\\textbf{dis}       &       0.5948  &        0.254     &     2.342  &         0.019        &        0.097    &        1.093     \\\\\n",
       "\\textbf{rad}       &       0.4892  &        0.162     &     3.027  &         0.002        &        0.172    &        0.806     \\\\\n",
       "\\textbf{ptratio}   &       0.5354  &        0.172     &     3.120  &         0.002        &        0.199    &        0.872     \\\\\n",
       "\\textbf{lstat}     &       0.2320  &        0.072     &     3.205  &         0.001        &        0.090    &        0.374     \\\\\n",
       "\\textbf{medv}      &       0.2486  &        0.070     &     3.535  &         0.000        &        0.111    &        0.386     \\\\\n",
       "\\textbf{intercept} &     -50.9489  &       10.325     &    -4.935  &         0.000        &      -71.185    &      -30.713     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  253\n",
       "Model:                            GLM   Df Residuals:                      244\n",
       "Model Family:                Binomial   Df Model:                            8\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -54.190\n",
       "Date:                Tue, 12 Sep 2023   Deviance:                       108.38\n",
       "Time:                        10:04:17   Pearson chi2:                     256.\n",
       "No. Iterations:                     9   Pseudo R-squ. (CS):             0.6156\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "indus         -0.1912      0.068     -2.822      0.005      -0.324      -0.058\n",
       "nox           51.1504     11.473      4.458      0.000      28.664      73.637\n",
       "age            0.0274      0.014      1.963      0.050    4.48e-05       0.055\n",
       "dis            0.5948      0.254      2.342      0.019       0.097       1.093\n",
       "rad            0.4892      0.162      3.027      0.002       0.172       0.806\n",
       "ptratio        0.5354      0.172      3.120      0.002       0.199       0.872\n",
       "lstat          0.2320      0.072      3.205      0.001       0.090       0.374\n",
       "medv           0.2486      0.070      3.535      0.000       0.111       0.386\n",
       "intercept    -50.9489     10.325     -4.935      0.000     -71.185     -30.713\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(Boston.drop(columns=[\"crim\",\"crim01\",\"zn\",\"chas\",\"rm\",\"tax\"]), crim01, test_size=0.5, random_state=0)\n",
    "X_train_ = X_train\n",
    "X_test_ = X_test\n",
    "X_train_[\"intercept\"] = 1\n",
    "X_test_[\"intercept\"] = 1\n",
    "\n",
    "glm = sm.GLM(y_train == \"1\",X_train_,family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything looks statistically significant, we can predict on the holdout data and compute the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth        0    1\n",
       "Predicted          \n",
       "0          111   23\n",
       "1           10  109"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = results.predict(exog=X_test_)\n",
    "labels = np.array([\"0\"]*X_test_.shape[0])\n",
    "labels[probs>0.5] = \"1\"\n",
    "confusion_table(labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13043478260869565"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels != y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error for logistic regression is 13%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth        0   1\n",
       "Predicted         \n",
       "0          120  39\n",
       "1            1  93"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(Boston.drop(columns=[\"crim\",\"crim01\",\"zn\",\"chas\",\"rm\",\"tax\"]), crim01, test_size=0.5, random_state=0)\n",
    "\n",
    "lda = LDA(store_covariance=True)\n",
    "lda.fit(X_train, y_train)\n",
    "lda_pred = lda.predict(X_test)\n",
    "confusion_table(lda_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15810276679841898"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lda_pred != y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA has an overall test error of 15.8%.\n",
    "\n",
    "But looking in details, type I error are much better: 1/(120 +1) = 0.8% compare to logistic regression that's an order of magnitude higher 10/(111+10) = 8%\n",
    "\n",
    "So we could use that as a strategy where we only look at Non-null hypothesis (aka when the crim is above the median)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth        0   1\n",
       "Predicted         \n",
       "0          120  37\n",
       "1            1  95"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(Boston.drop(columns=[\"crim\",\"crim01\",\"zn\",\"chas\",\"rm\",\"tax\"]), crim01, test_size=0.5, random_state=0)\n",
    "\n",
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(X_train, y_train)\n",
    "qda_pred = qda.predict(X_test)\n",
    "confusion_table(qda_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15019762845849802"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(qda_pred != y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error test rate for QDA is 15%.\n",
    "As for LDA, type I error is very low, but unlike it, type II error is a bit lower. So overall it might be a better strategy to use than LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth        0    1\n",
       "Predicted          \n",
       "0          110   27\n",
       "1           11  105"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(Boston.drop(columns=[\"crim\",\"crim01\",\"zn\",\"chas\",\"rm\",\"tax\"]), crim01, test_size=0.5, random_state=0)\n",
    "\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, y_train)\n",
    "NB_pred = NB.predict(X_test)\n",
    "confusion_table(NB_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15019762845849802"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(NB_pred != y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Naive Bayes, the overall test error is 15%, so the same as for QDA.\n",
    "\n",
    "Now, depending on what we are mostly interested (i.e. the null/non-null hypothesis), one might choose one or the another.\n",
    "\n",
    "In this case, I would imagine that people are more worried about a prediction of low crime rate and buying a house with high crime rate. So we are interested in reducing the error when we predict the null hypothesis (crim01 = 0), but we end up with a true class non null (crim01 = 1). This is a type II error (a.k.a. a false negative), when we said crim rate will be low but it will be high instead, and that's the top right corner of the confusion table.\n",
    "\n",
    "So back to our method comparison, if we want to reduce the type II error, we would choose Naive Bayes over QDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1: # predicted with higher crim rate: 129, # with actual high crime rate 105, test error rate 18.6%\n",
      "K=2: # predicted with higher crim rate: 151, # with actual high crime rate 117, test error rate 22.5%\n",
      "K=3: # predicted with higher crim rate: 137, # with actual high crime rate 112, test error rate 18.2%\n",
      "K=4: # predicted with higher crim rate: 152, # with actual high crime rate 114, test error rate 25.0%\n",
      "K=5: # predicted with higher crim rate: 137, # with actual high crime rate 108, test error rate 21.2%\n"
     ]
    }
   ],
   "source": [
    "for K in range(1,6):\n",
    "    knn = KNeighborsClassifier(n_neighbors=K)\n",
    "    knn_pred = knn.fit(X_train.values, y_train).predict(X_test.values)\n",
    "    C = confusion_table(knn_pred, y_test)\n",
    "    templ = (\"K={0:d}: # predicted with higher crim rate: {1:>2},\" +\n",
    "             \" # with actual high crime rate {2:d}, test error rate {3:.1%}\")\n",
    "    pred = C.loc[\"0\"].sum()\n",
    "    high_crim_rate = C.loc[\"0\", \"0\"]\n",
    "    print(templ.format(K, pred, high_crim_rate, 1-(high_crim_rate/pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the KNN, the lowest error rate for the case we are interested in (when we predict low rate crime) is for K=1 and is 18.6%. Naive Bayes is still a better option."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
